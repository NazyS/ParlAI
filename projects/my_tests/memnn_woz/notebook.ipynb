{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('parlai': conda)"
  },
  "interpreter": {
   "hash": "fcffad88e659484ed739abd15ee1932971ecc38ab6a67b7afefe7e71528aded0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "candidates = []\n",
    "\n",
    "path = '/home/nazar/ParlAI/data/WoZ/'\n",
    "fnames = ['woz_train_en.json', 'woz_validate_en.json', 'woz_test_en.json']\n",
    "\n",
    "for fname in fnames:\n",
    "\n",
    "    with open(path+fname, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for dialogue in data:\n",
    "        for line in dialogue['dialogue']:\n",
    "            for el in [':'.join(turn_labels) for turn_labels in line['turn_label']]:\n",
    "                candidates.append(el) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "candidates = set(candidates)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "with open('labels_full.dict', 'a') as f:\n",
    "    for el in candidates:\n",
    "        f.write(el+'\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# dialog babi task 5 checking labels"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "labels = []\n",
    "with open('../../../data/dialog-bAbI/dialog-bAbI-tasks/dialog-babi-task5-full-dialogs-trn.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        if '\\t' in line:\n",
    "            strings = line.strip().split('\\t')\n",
    "            labels.append(\n",
    "                strings[-1]\n",
    "            )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "labels = set(labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "len(labels)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1098"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "len(labels)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1098"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "with open('task5/candidates.txt', 'a') as f:\n",
    "    for el in labels:\n",
    "        f.write(el+'\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from parlai.scripts.display_data import DisplayData"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "DisplayData.main(\n",
    "    task='fromfile:parlaiformat',\n",
    "    fromfile_datapath='flow_data/testflow',\n",
    "    fromfile_datatype_extension=True\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "15:48:49 | Opt:\n",
      "15:48:49 |     allow_missing_init_opts: False\n",
      "15:48:49 |     batchsize: 1\n",
      "15:48:49 |     datapath: /home/nazar/ParlAI/data\n",
      "15:48:49 |     datatype: train:ordered\n",
      "15:48:49 |     dict_class: None\n",
      "15:48:49 |     display_add_fields: \n",
      "15:48:49 |     download_path: None\n",
      "15:48:49 |     dynamic_batching: None\n",
      "15:48:49 |     fromfile_datapath: flow_data/testflow\n",
      "15:48:49 |     fromfile_datatype_extension: True\n",
      "15:48:49 |     hide_labels: False\n",
      "15:48:49 |     ignore_agent_reply: True\n",
      "15:48:49 |     image_cropsize: 224\n",
      "15:48:49 |     image_mode: raw\n",
      "15:48:49 |     image_size: 256\n",
      "15:48:49 |     init_model: None\n",
      "15:48:49 |     init_opt: None\n",
      "15:48:49 |     is_debug: False\n",
      "15:48:49 |     loglevel: info\n",
      "15:48:49 |     max_display_len: 1000\n",
      "15:48:49 |     model: None\n",
      "15:48:49 |     model_file: None\n",
      "15:48:49 |     multitask_weights: [1]\n",
      "15:48:49 |     mutators: None\n",
      "15:48:49 |     num_examples: 10\n",
      "15:48:49 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': 'flow_data/testflow', 'fromfile_datatype_extension': True}\"\n",
      "15:48:49 |     parlai_home: /home/nazar/ParlAI\n",
      "15:48:49 |     starttime: Jul20_15-48\n",
      "15:48:49 |     task: fromfile:parlaiformat\n",
      "15:48:49 |     verbose: False\n",
      "15:48:49 | Current ParlAI commit: 525fe6061d35552b6f530a9bf4d84f7f0bbafdf3\n",
      "15:48:49 | creating task(s): fromfile:parlaiformat\n",
      "15:48:49 | Loading ParlAI text data: flow_data/testflow_train.txt\n",
      "\u001b[1;31m- - - NEW EPISODE: flow_data/testflow_train.txt - - -\u001b[0;0m\n",
      "\u001b[0mHello\u001b[0;0m\n",
      "   \u001b[1;94mGood day, [Sir/Madam]! Can I speak with [NAME], please?\u001b[0;0m\n",
      "\u001b[1;31m- - - NEW EPISODE: flow_data/testflow_train.txt - - -\u001b[0;0m\n",
      "\u001b[0mHi\u001b[0;0m\n",
      "   \u001b[1;94mGood day, [Sir/Madam]! Can I speak with [NAME], please?\u001b[0;0m\n",
      "\u001b[1;31m- - - NEW EPISODE: flow_data/testflow_train.txt - - -\u001b[0;0m\n",
      "\u001b[0mGreetings!\u001b[0;0m\n",
      "   \u001b[1;94mGood day, [Sir/Madam]! Can I speak with [NAME], please?\u001b[0;0m\n",
      "\u001b[1;31m- - - NEW EPISODE: flow_data/testflow_train.txt - - -\u001b[0;0m\n",
      "\u001b[0mHi, How is it going?\u001b[0;0m\n",
      "   \u001b[1;94mGood day, [Sir/Madam]! Can I speak with [NAME], please?\u001b[0;0m\n",
      "\u001b[1;31m- - - NEW EPISODE: flow_data/testflow_train.txt - - -\u001b[0;0m\n",
      "\u001b[0mHow are you doing?\u001b[0;0m\n",
      "   \u001b[1;94mGood day, [Sir/Madam]! Can I speak with [NAME], please?\u001b[0;0m\n",
      "\u001b[1;31m- - - NEW EPISODE: flow_data/testflow_train.txt - - -\u001b[0;0m\n",
      "\u001b[0mNice to meet you.\u001b[0;0m\n",
      "   \u001b[1;94mGood day, [Sir/Madam]! Can I speak with [NAME], please?\u001b[0;0m\n",
      "\u001b[1;31m- - - NEW EPISODE: flow_data/testflow_train.txt - - -\u001b[0;0m\n",
      "\u001b[0mHow do you do?\u001b[0;0m\n",
      "   \u001b[1;94mGood day, [Sir/Madam]! Can I speak with [NAME], please?\u001b[0;0m\n",
      "\u001b[1;31m- - - NEW EPISODE: flow_data/testflow_train.txt - - -\u001b[0;0m\n",
      "\u001b[0mHi, nice to meet you.\u001b[0;0m\n",
      "   \u001b[1;94mGood day, [Sir/Madam]! Can I speak with [NAME], please?\u001b[0;0m\n",
      "\u001b[1;31m- - - NEW EPISODE: flow_data/testflow_train.txt - - -\u001b[0;0m\n",
      "\u001b[0mIt is a pleasure to meet you.\u001b[0;0m\n",
      "   \u001b[1;94mGood day, [Sir/Madam]! Can I speak with [NAME], please?\u001b[0;0m\n",
      "\u001b[1;31m- - - NEW EPISODE: flow_data/testflow_train.txt - - -\u001b[0;0m\n",
      "\u001b[0mTop of the morning to you!\u001b[0;0m\n",
      "   \u001b[1;94mGood day, [Sir/Madam]! Can I speak with [NAME], please?\u001b[0;0m\n",
      "15:48:49 | loaded 11 episodes with a total of 11 examples\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from parlai.scripts.interactive import Interactive\n",
    "\n",
    "Interactive.main(\n",
    "    model_file='task5-3/pos_enc/memnn_dialog_babi',\n",
    "    eval_candidates='fixed',\n",
    "    fixed_candidates_path='task5-3/test_cand.txt',\n",
    "    # repeat_blocking_heuristic=False,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating test set with greetings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# text:hello\tlabels:hi, how are you?\tepisode_done:True\n",
    "\n",
    "# text:hi\tlabels:hello hello\tepisode_done:True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "response = 'Good day, [Sir/Madam]! Can I speak with [NAME], please?'\n",
    "\n",
    "with open('flow_data/responses/greetings.txt') as greetings:\n",
    "    with open('flow_data/testflow_train.txt', 'a') as dataset:\n",
    "        for line in greetings.readlines():\n",
    "            dataset.write(\n",
    "                f'text:{line.strip()}\\tlabels:{response}\\tepisode_done:True\\n\\n'\n",
    "            )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# storyline class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "import os\n",
    "\n",
    "test_stucture = {\n",
    "    '0':['1'],\n",
    "    '1':['1a', '1b', '1c'],\n",
    "    '1a':['2a'],\n",
    "    '1b':['2b'],\n",
    "    '1c':['2c'],\n",
    "    '2b':['2b-1', '2b-2', '2b-3'],\n",
    "    '2b-1':['3b-1'],\n",
    "    '2b-2':['3b-2'],\n",
    "    '2b-3':['3b-3'],\n",
    "    '2a':['2a-1', '2a-2', '2a-3'],\n",
    "    '2a-1':['3a-1'],\n",
    "    '2a-2':['5a-2'],\n",
    "    '2a-3':['3a-3'],\n",
    "    '3a-3':['4a-3-a', '4a-3-b'],\n",
    "    '4a-3-a':['5a-2'],\n",
    "    '4a-3-b':['5a-3']\n",
    "}\n",
    "\n",
    "class Story():\n",
    "    def __init__(\n",
    "        self,\n",
    "        structure=test_stucture,\n",
    "        folder='flow_data/responses'\n",
    "    ) -> None:\n",
    "        self.folder = folder\n",
    "        self.structure = structure\n",
    "\n",
    "        self.scripts = []\n",
    "        self.recursive_build_scripts('', '0')\n",
    "\n",
    "        self.stories = []\n",
    "        self.build_stories()\n",
    "\n",
    "\n",
    "    def add_connection(self, story, out_node):\n",
    "        return story + out_node + ' '\n",
    "\n",
    "    def recursive_build_scripts(self, story, inp):\n",
    "        story = self.add_connection(story, inp)        \n",
    "        connections = self.structure.get(inp)\n",
    "        try:\n",
    "            for node in connections:\n",
    "                self.recursive_build_scripts(story, node)\n",
    "        except:\n",
    "            self.scripts.append(\n",
    "                story\n",
    "            )\n",
    "    \n",
    "    def recursive_build_story(self, story, nodes):\n",
    "        try:\n",
    "            filename = f'response_{nodes[0]}.txt'\n",
    "            path = os.path.join(self.folder, filename)\n",
    "            with open(path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                if len(lines) == 0:\n",
    "                    self.stories.append(story)\n",
    "                else:\n",
    "                    for line in lines:\n",
    "                        self.recursive_build_story(\n",
    "                            story + line,\n",
    "                            nodes[1:]\n",
    "                        )\n",
    "        except:\n",
    "            self.stories.append(story)\n",
    "\n",
    "    def build_stories(self):\n",
    "        for script in self.scripts:\n",
    "            nodes = script.split()\n",
    "            self.recursive_build_story('', nodes)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.stories[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.stories)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "stories = Story()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "print(\n",
    "    stories[100]\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hi\n",
      "good day, can I speak with [NAME], please?\n",
      "it's me\n",
      "my boss, with whom you spoke about the loan, asked me to call you back and clarify when you plan to make a payment, for how much and in which bank?\n",
      "probably next month or so\n",
      "[ESCALATING FURTHER]\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "i = 0\n",
    "for story in stories.stories:\n",
    "    if 'reach' in story:\n",
    "        # print(story)\n",
    "        i +=1\n",
    "\n",
    "i        "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "nodes = []\n",
    "for key, vals in test_stucture.items():\n",
    "    nodes.append(key)\n",
    "    for el in vals:\n",
    "        nodes.append(el)\n",
    "\n",
    "nodes = set(nodes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "import os\n",
    "\n",
    "for node in nodes:\n",
    "    folderpath = 'flow_data/responses'\n",
    "    filepath = os.path.join(folderpath, f'response_{node}.txt')\n",
    "    if not os.path.exists(filepath):\n",
    "        open(filepath, 'w').close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}