{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('parlai': conda)"
  },
  "interpreter": {
   "hash": "fcffad88e659484ed739abd15ee1932971ecc38ab6a67b7afefe7e71528aded0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "candidates = []\n",
    "\n",
    "path = '/home/nazar/ParlAI/data/WoZ/'\n",
    "fnames = ['woz_train_en.json', 'woz_validate_en.json', 'woz_test_en.json']\n",
    "\n",
    "for fname in fnames:\n",
    "\n",
    "    with open(path+fname, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for dialogue in data:\n",
    "        for line in dialogue['dialogue']:\n",
    "            for el in [':'.join(turn_labels) for turn_labels in line['turn_label']]:\n",
    "                candidates.append(el) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "candidates = set(candidates)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('labels_full.dict', 'a') as f:\n",
    "    for el in candidates:\n",
    "        f.write(el+'\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# dialog babi task 5 checking labels"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "labels = []\n",
    "with open('../../../data/dialog-bAbI/dialog-bAbI-tasks/dialog-babi-task5-full-dialogs-trn.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        if '\\t' in line:\n",
    "            strings = line.strip().split('\\t')\n",
    "            labels.append(\n",
    "                strings[-1]\n",
    "            )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "labels = set(labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('task5/candidates.txt', 'a') as f:\n",
    "    for el in labels:\n",
    "        f.write(el+'\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from parlai.scripts.display_data import DisplayData"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "DisplayData.main(\n",
    "    task='fromfile:parlaiformat',\n",
    "    fromfile_datapath='flow_data/testflow',\n",
    "    fromfile_datatype_extension=True\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from parlai.scripts.interactive import Interactive\n",
    "\n",
    "Interactive.main(\n",
    "    model_file='task5-3/pos_enc/memnn_dialog_babi',\n",
    "    eval_candidates='fixed',\n",
    "    fixed_candidates_path='task5-3/test_cand.txt',\n",
    "    # repeat_blocking_heuristic=False,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating test set with greetings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# text:hello\tlabels:hi, how are you?\tepisode_done:True\n",
    "\n",
    "# text:hi\tlabels:hello hello\tepisode_done:True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "response = 'Good day, [Sir/Madam]! Can I speak with [NAME], please?'\n",
    "\n",
    "with open('flow_data/responses/greetings.txt') as greetings:\n",
    "    with open('flow_data/testflow_train.txt', 'a') as dataset:\n",
    "        for line in greetings.readlines():\n",
    "            dataset.write(\n",
    "                f'text:{line.strip()}\\tlabels:{response}\\tepisode_done:True\\n\\n'\n",
    "            )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# storyline class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import os\n",
    "\n",
    "test_stucture = {\n",
    "    '0':['1'],\n",
    "    '1':['1a', '1b', '1c'],\n",
    "    '1a':['2a'],\n",
    "    '1b':['2b'],\n",
    "    '1c':['2c'],\n",
    "    '2b':['2b-1', '2b-2', '2b-3'],\n",
    "    '2b-1':['3b-1'],\n",
    "    '2b-2':['3b-2'],\n",
    "    '2b-3':['3b-3'],\n",
    "    '2a':['2a-2', '2a-3'],\n",
    "    # '2a':['2a-1', '2a-2', '2a-3'],\n",
    "    # '2a-1':['3a-1'],\n",
    "    '2a-2':['5a-2'],\n",
    "    '2a-3':['3a-3'],\n",
    "    '3a-3':['4a-3-a', '4a-3-b'],\n",
    "    '4a-3-a':['5a-2'],\n",
    "    '4a-3-b':['5a-3']\n",
    "}\n",
    "\n",
    "class Story():\n",
    "    def __init__(\n",
    "        self,\n",
    "        structure=test_stucture,\n",
    "        folder='flow_data/flow',\n",
    "        version=3,\n",
    "        # dataset_path='flow_data/flow/flow_train_2.txt',\n",
    "        candidates_outpath='flow_data/flow/candidates.txt'\n",
    "    ) -> None:\n",
    "        self.folder = folder\n",
    "        self.structure = structure\n",
    "\n",
    "        self.types = ['train', 'valid']\n",
    "        self.prefix = 'flow'\n",
    "        # self.dataset_path = dataset_path\n",
    "        self.version = version\n",
    "        self.candidates_outpath = candidates_outpath\n",
    "\n",
    "        self.scripts = []\n",
    "        self.recursive_build_scripts('', '0')\n",
    "\n",
    "        self.stories = {suffix:[] for suffix in self.types}\n",
    "        self.build_stories()\n",
    "\n",
    "\n",
    "    def add_connection(self, story, out_node):\n",
    "        return story + out_node + ' '\n",
    "\n",
    "    def recursive_build_scripts(self, story, inp):\n",
    "        story = self.add_connection(story, inp)        \n",
    "        connections = self.structure.get(inp)\n",
    "        try:\n",
    "            for node in connections:\n",
    "                self.recursive_build_scripts(story, node)\n",
    "        except:\n",
    "            self.scripts.append(\n",
    "                story\n",
    "            )\n",
    "    \n",
    "    def recursive_build_story(self, story, nodes, suffix):\n",
    "        try:\n",
    "            filename = f'response_{nodes[0]}.txt'\n",
    "            path = os.path.join(self.folder, 'responses', suffix, filename)\n",
    "            with open(path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                if len(lines) == 0:\n",
    "                    self.stories[suffix].append(story)\n",
    "                else:\n",
    "                    for line in lines:\n",
    "                        self.recursive_build_story(\n",
    "                            story + line,\n",
    "                            nodes[1:],\n",
    "                            suffix\n",
    "                        )\n",
    "        except:\n",
    "            self.stories[suffix].append(story)\n",
    "\n",
    "    def build_stories(self):\n",
    "        for suffix in self.types:\n",
    "            for script in self.scripts:\n",
    "                nodes = script.split()\n",
    "                self.recursive_build_story('', nodes, suffix)\n",
    "\n",
    "\n",
    "    # def __getitem__(self, idx):\n",
    "    #     return self.stories[idx]\n",
    "    \n",
    "    # def __len__(self):\n",
    "    #     return len(self.stories)\n",
    "\n",
    "    def to_ParlAIDialogTeacher_format(self, story):\n",
    "        lines = story.split('\\n')\n",
    "        string = ''\n",
    "        prefix = ['text:', 'labels:']\n",
    "\n",
    "        for i, line in enumerate(lines[:-2]):\n",
    "            if i%2!=0:\n",
    "                string += prefix[1]+line+'\\n'\n",
    "            else:\n",
    "                string += prefix[0]+line + '\\t'\n",
    "        \n",
    "\n",
    "        string += prefix[1] + lines[-2] + '\\tepisode_done:True\\n\\n'\n",
    "        return string\n",
    "\n",
    "    \n",
    "    def to_FbDeprecatedDialogTeacher_format(self, story):\n",
    "        lines = story.split('\\n')\n",
    "        string = ''\n",
    "        counter = 1\n",
    "        # from itertools import cycle\n",
    "        # sep = cycle(['\\t', '\\n'])\n",
    "        # for line in lines[:-1]:\n",
    "        #     string += line + next(sep)\n",
    "        \n",
    "        for i in range((len(lines)-1)//2):\n",
    "            string += str(counter) + ' ' + lines[2*i] + '\\t' + lines[2*i+1] + '\\n'\n",
    "            counter += 1\n",
    "\n",
    "        string += '\\n'\n",
    "        return string\n",
    "\n",
    "\n",
    "    def story_to_ds_format(self, story, teacher='fb'):\n",
    "        if teacher == 'parali':\n",
    "            return self.to_ParlAIDialogTeacher_format(story)\n",
    "        elif teacher == 'fb':\n",
    "            return self.to_FbDeprecatedDialogTeacher_format(story)\n",
    "        \n",
    "\n",
    "    def build_dataset(self):\n",
    "        for suffix in self.types:\n",
    "            path = self.dataset_path(suffix)\n",
    "            with open(path, 'w') as f:\n",
    "                for story in self.stories[suffix]:\n",
    "                    f.write(self.story_to_ds_format(story))\n",
    "\n",
    "    def build_candidates(self, outpath=None):\n",
    "        all_labels = []\n",
    "        for key in self.stories.keys():\n",
    "            for story in self.stories[key]:\n",
    "                lines = story.split('\\n')\n",
    "                labels = lines[1::2]\n",
    "                all_labels.extend(labels)\n",
    "\n",
    "        all_labels = list(set(all_labels))\n",
    "        \n",
    "        if outpath is None:\n",
    "            outpath = self.candidates_outpath\n",
    "        \n",
    "        with open(outpath, 'w') as f:\n",
    "            for cand in all_labels:\n",
    "                f.write(cand+'\\n')\n",
    "\n",
    "    def dataset_path(self, suffix):\n",
    "        filename = '_'.join([self.prefix, suffix, str(self.version)]) + '.txt'\n",
    "        return os.path.join(self.folder, filename)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "stories = Story()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "story = stories.stories['train'][0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "stories.to_FbDeprecatedDialogTeacher_format(story)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"1 hello\\tgood day, can I speak with [NAME], please?\\n2 yeah, here he is\\tmy boss, with whom you spoke about the loan, asked me to call you back and clarify when you plan to make a payment, for how much and in which bank?\\n3 i don't know\\t[ESCALATING FURTHER]\\n\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "print(stories.to_FbDeprecatedDialogTeacher_format(story))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 hello\tgood day, can I speak with [NAME], please?\n",
      "2 yeah, here he is\tmy boss, with whom you spoke about the loan, asked me to call you back and clarify when you plan to make a payment, for how much and in which bank?\n",
      "3 i don't know\t[ESCALATING FURTHER]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "stories.build_dataset()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "stories.build_candidates()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "nodes = []\n",
    "for key, vals in test_stucture.items():\n",
    "    nodes.append(key)\n",
    "    for el in vals:\n",
    "        nodes.append(el)\n",
    "\n",
    "nodes = set(nodes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import os\n",
    "\n",
    "for subset in ['train', 'valid']:\n",
    "    for node in nodes:\n",
    "        folderpath = 'flow_data/responses'\n",
    "        filepath = os.path.join(folderpath, subset, f'response_{node}.txt')\n",
    "        if not os.path.exists(filepath):\n",
    "            open(filepath, 'w').close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from parlai.scripts.build_candidates import BuildCandidates\n",
    "\n",
    "BuildCandidates.main(\n",
    "    datapath='flow_data',\n",
    "    task='testflow:train2',\n",
    "    outfile='flow_test/candidates.txt'\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from parlai.scripts.display_data import DisplayData\n",
    "\n",
    "# DisplayData.main(\n",
    "#     # task='flow:flow:2:datapath=flow_data,dialog_babi:task:5',\n",
    "#     # task='dialog_babi:task:5',\n",
    "#     task='flow:flow:2:candidates=fixed:fcp=flow_data/candidates.txt:datapath=flow_data',\n",
    "#     init_opts='flow_test/flow_test/model/memnn_prtr.dict.opt',\n",
    "#     allow_missing_opts=True,\n",
    "#     # verbose=True,\n",
    "#     # display_add_fields='label_candidates',\n",
    "# )\n",
    "\n",
    "DisplayData.main(\n",
    "    task='flow:flow:3',\n",
    "    verbose=True,\n",
    "    datapath='flow_data',\n",
    "    # display_add_fields='label_candidates',\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "18:31:20 | Opt:\n",
      "18:31:20 |     allow_missing_init_opts: False\n",
      "18:31:20 |     batchsize: 1\n",
      "18:31:20 |     datapath: flow_data\n",
      "18:31:20 |     datatype: train:ordered\n",
      "18:31:20 |     dict_class: None\n",
      "18:31:20 |     display_add_fields: \n",
      "18:31:20 |     download_path: None\n",
      "18:31:20 |     dynamic_batching: None\n",
      "18:31:20 |     hide_labels: False\n",
      "18:31:20 |     ignore_agent_reply: True\n",
      "18:31:20 |     image_cropsize: 224\n",
      "18:31:20 |     image_mode: raw\n",
      "18:31:20 |     image_size: 256\n",
      "18:31:20 |     init_model: None\n",
      "18:31:20 |     init_opt: None\n",
      "18:31:20 |     is_debug: False\n",
      "18:31:20 |     loglevel: info\n",
      "18:31:20 |     max_display_len: 1000\n",
      "18:31:20 |     model: None\n",
      "18:31:20 |     model_file: None\n",
      "18:31:20 |     multitask_weights: [1]\n",
      "18:31:20 |     mutators: None\n",
      "18:31:20 |     num_examples: 10\n",
      "18:31:20 |     override: \"{'task': 'flow:flow:3', 'verbose': True, 'datapath': 'flow_data'}\"\n",
      "18:31:20 |     parlai_home: /home/nazar/ParlAI\n",
      "18:31:20 |     starttime: Jul27_18-31\n",
      "18:31:20 |     task: flow:flow:3\n",
      "18:31:20 |     verbose: True\n",
      "18:31:20 | Current ParlAI commit: cd646ddf9bb6b98119de45bb1454eae4bad57e5f\n",
      "18:31:20 | creating task(s): flow:flow:3\n",
      "18:31:20 | loading fbdialog data: flow_data/flow_train_3.txt\n",
      "\u001b[0;34m[id]:\u001b[0;0m \u001b[0mflow:flow:3\u001b[0;0m\n",
      "\u001b[0;34m[text]:\u001b[0;0m \u001b[1mhello\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94mgood day, can I speak with [NAME], please?\u001b[0;0m\n",
      "\u001b[0;34m[label_candidates]:\u001b[0;0m \u001b[0mThank you for your cooperation. Good luck.|thank you for the information|api_call check_ptp|[ESCALATING FURTHER]|okay, thank you, i will try to reach later|... (5 of 10 shown)\u001b[0;0m\n",
      "~~\n",
      "\u001b[0;34m[id]:\u001b[0;0m \u001b[0mflow:flow:3\u001b[0;0m\n",
      "\u001b[0;34m[text]:\u001b[0;0m \u001b[1myeah, here he is\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94mmy boss, with whom you spoke about the loan, asked me to call you back and clarify when you plan to make a payment, for how much and in which bank?\u001b[0;0m\n",
      "\u001b[0;34m[label_candidates]:\u001b[0;0m \u001b[0mThank you for your cooperation. Good luck.|thank you for the information|api_call check_ptp|[ESCALATING FURTHER]|okay, thank you, i will try to reach later|... (5 of 10 shown)\u001b[0;0m\n",
      "~~\n",
      "\u001b[0;34m[id]:\u001b[0;0m \u001b[0mflow:flow:3\u001b[0;0m\n",
      "\u001b[0;34m[text]:\u001b[0;0m \u001b[1mi don't know\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94m[ESCALATING FURTHER]\u001b[0;0m\n",
      "\u001b[0;34m[label_candidates]:\u001b[0;0m \u001b[0mThank you for your cooperation. Good luck.|thank you for the information|api_call check_ptp|[ESCALATING FURTHER]|okay, thank you, i will try to reach later|... (5 of 10 shown)\u001b[0;0m\n",
      "\u001b[1;31m- - - - - - - END OF EPISODE - - - - - - - - - -\u001b[0;0m\n",
      "~~\n",
      "\u001b[0;34m[id]:\u001b[0;0m \u001b[0mflow:flow:3\u001b[0;0m\n",
      "\u001b[0;34m[text]:\u001b[0;0m \u001b[1mhello\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94mgood day, can I speak with [NAME], please?\u001b[0;0m\n",
      "\u001b[0;34m[label_candidates]:\u001b[0;0m \u001b[0mThank you for your cooperation. Good luck.|thank you for the information|api_call check_ptp|[ESCALATING FURTHER]|okay, thank you, i will try to reach later|... (5 of 10 shown)\u001b[0;0m\n",
      "~~\n",
      "\u001b[0;34m[id]:\u001b[0;0m \u001b[0mflow:flow:3\u001b[0;0m\n",
      "\u001b[0;34m[text]:\u001b[0;0m \u001b[1myeah, here he is\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94mmy boss, with whom you spoke about the loan, asked me to call you back and clarify when you plan to make a payment, for how much and in which bank?\u001b[0;0m\n",
      "\u001b[0;34m[label_candidates]:\u001b[0;0m \u001b[0mThank you for your cooperation. Good luck.|thank you for the information|api_call check_ptp|[ESCALATING FURTHER]|okay, thank you, i will try to reach later|... (5 of 10 shown)\u001b[0;0m\n",
      "~~\n",
      "\u001b[0;34m[id]:\u001b[0;0m \u001b[0mflow:flow:3\u001b[0;0m\n",
      "\u001b[0;34m[text]:\u001b[0;0m \u001b[1mnot sure\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94m[ESCALATING FURTHER]\u001b[0;0m\n",
      "\u001b[0;34m[label_candidates]:\u001b[0;0m \u001b[0mThank you for your cooperation. Good luck.|thank you for the information|api_call check_ptp|[ESCALATING FURTHER]|okay, thank you, i will try to reach later|... (5 of 10 shown)\u001b[0;0m\n",
      "\u001b[1;31m- - - - - - - END OF EPISODE - - - - - - - - - -\u001b[0;0m\n",
      "~~\n",
      "\u001b[0;34m[id]:\u001b[0;0m \u001b[0mflow:flow:3\u001b[0;0m\n",
      "\u001b[0;34m[text]:\u001b[0;0m \u001b[1mhello\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94mgood day, can I speak with [NAME], please?\u001b[0;0m\n",
      "\u001b[0;34m[label_candidates]:\u001b[0;0m \u001b[0mThank you for your cooperation. Good luck.|thank you for the information|api_call check_ptp|[ESCALATING FURTHER]|okay, thank you, i will try to reach later|... (5 of 10 shown)\u001b[0;0m\n",
      "~~\n",
      "\u001b[0;34m[id]:\u001b[0;0m \u001b[0mflow:flow:3\u001b[0;0m\n",
      "\u001b[0;34m[text]:\u001b[0;0m \u001b[1myeah, here he is\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94mmy boss, with whom you spoke about the loan, asked me to call you back and clarify when you plan to make a payment, for how much and in which bank?\u001b[0;0m\n",
      "\u001b[0;34m[label_candidates]:\u001b[0;0m \u001b[0mThank you for your cooperation. Good luck.|thank you for the information|api_call check_ptp|[ESCALATING FURTHER]|okay, thank you, i will try to reach later|... (5 of 10 shown)\u001b[0;0m\n",
      "~~\n",
      "\u001b[0;34m[id]:\u001b[0;0m \u001b[0mflow:flow:3\u001b[0;0m\n",
      "\u001b[0;34m[text]:\u001b[0;0m \u001b[1mlater\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94m[ESCALATING FURTHER]\u001b[0;0m\n",
      "\u001b[0;34m[label_candidates]:\u001b[0;0m \u001b[0mThank you for your cooperation. Good luck.|thank you for the information|api_call check_ptp|[ESCALATING FURTHER]|okay, thank you, i will try to reach later|... (5 of 10 shown)\u001b[0;0m\n",
      "\u001b[1;31m- - - - - - - END OF EPISODE - - - - - - - - - -\u001b[0;0m\n",
      "~~\n",
      "\u001b[0;34m[id]:\u001b[0;0m \u001b[0mflow:flow:3\u001b[0;0m\n",
      "\u001b[0;34m[text]:\u001b[0;0m \u001b[1mhello\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94mgood day, can I speak with [NAME], please?\u001b[0;0m\n",
      "\u001b[0;34m[label_candidates]:\u001b[0;0m \u001b[0mThank you for your cooperation. Good luck.|thank you for the information|api_call check_ptp|[ESCALATING FURTHER]|okay, thank you, i will try to reach later|... (5 of 10 shown)\u001b[0;0m\n",
      "~~\n",
      "18:31:20 | loaded 2135 episodes with a total of 6664 examples\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from parlai.scripts.eval_model import EvalModel\n",
    "\n",
    "EvalModel.main(\n",
    "    # task='flow:flow:2:datapath=flow_data,dialog_babi:task:5',\n",
    "    # task='dialog_babi:task:5',\n",
    "    task='flow:flow:2',\n",
    "    init_opt='model/memnn_prtr.dict.opt',\n",
    "    allow_missing_init_opts=True,\n",
    "    datapath='../flow_data',\n",
    "    # datatype='train:evalmode',\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "17:23:23 | \u001b[33mThe \"evaltask\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"eval_batchsize\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"eval_dynamic_batching\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"num_workers\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"num_epochs\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"max_train_time\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"max_train_steps\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"log_every_n_steps\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"validation_every_n_secs\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"validation_every_n_steps\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"save_every_n_secs\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"save_after_valid\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"validation_every_n_epochs\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"validation_max_exs\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"short_final_eval\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"validation_patience\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"validation_metric\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"validation_metric_mode\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"validation_cutoff\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"validation_share_agent\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"wandb_log\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"wandb_name\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"wandb_project\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"wandb_entity\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"dict_maxexs\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"dict_include_valid\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"dict_include_test\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mThe \"starttime\" key in model/memnn_prtr.dict.opt will not be loaded, because it does not exist in the target opt.\u001b[0m\n",
      "17:23:23 | \u001b[33mOverriding opt[\"datatype\"] to valid (previously: train)\u001b[0m\n",
      "17:23:23 | \u001b[33mOverriding opt[\"task\"] to flow:flow:2 (previously: flow:flow:train:2)\u001b[0m\n",
      "17:23:23 | \u001b[33mOverriding opt[\"init_opt\"] to model/memnn_prtr.dict.opt (previously: None)\u001b[0m\n",
      "17:23:23 | \u001b[33mOverriding opt[\"allow_missing_init_opts\"] to True (previously: False)\u001b[0m\n",
      "17:23:23 | \u001b[33mOverriding opt[\"init_model\"] to None (previously: model/memnn_prtr.checkpoint)\u001b[0m\n",
      "17:23:23 | \u001b[33mOverriding opt[\"num_epochs\"] to 100.0 (previously: 1000.0)\u001b[0m\n",
      "17:23:23 | \u001b[33mOverriding opt[\"save_every_n_secs\"] to -1 (previously: 100.0)\u001b[0m\n",
      "17:23:23 | \u001b[33mOverriding opt[\"rank_candidates\"] to False (previously: True)\u001b[0m\n",
      "17:23:23 | \u001b[33mOverriding opt[\"dict_file\"] to model/memnn_prtr.dict (previously: model/memnn_prtr.checkpoint.dict)\u001b[0m\n",
      "17:23:23 | Using CUDA\n",
      "17:23:23 | loading dictionary from model/memnn_prtr.dict\n",
      "17:23:23 | num words = 148\n",
      "17:23:23 | Total parameters: 19,968 (19,968 trainable)\n",
      "17:23:23 | Loading existing model parameters from model/memnn_prtr\n",
      "17:23:23 | Loading fixed candidate set from candidates.txt\n",
      "17:23:23 | Loading fixed candidate set vectors from model/memnn_prtr.candidates.vecs\n",
      "17:23:23 | Loading fixed candidate set encodings from model/memnn_prtr.candidates.encs\n",
      "17:23:23 | Opt:\n",
      "17:23:23 |     adafactor_eps: '[1e-30, 0.001]'\n",
      "17:23:23 |     adam_eps: 1e-08\n",
      "17:23:23 |     add_p1_after_newln: True\n",
      "17:23:23 |     aggregate_micro: False\n",
      "17:23:23 |     allow_missing_init_opts: True\n",
      "17:23:23 |     area_under_curve_class: None\n",
      "17:23:23 |     area_under_curve_digits: -1\n",
      "17:23:23 |     batchsize: 100\n",
      "17:23:23 |     betas: '[0.9, 0.999]'\n",
      "17:23:23 |     bpe_add_prefix_space: None\n",
      "17:23:23 |     bpe_debug: False\n",
      "17:23:23 |     bpe_dropout: None\n",
      "17:23:23 |     bpe_merge: None\n",
      "17:23:23 |     bpe_vocab: None\n",
      "17:23:23 |     candidates: fixed\n",
      "17:23:23 |     cap_num_predictions: 100\n",
      "17:23:23 |     datapath: ../flow_data\n",
      "17:23:23 |     datatype: valid\n",
      "17:23:23 |     delimiter: '\\n'\n",
      "17:23:23 |     dict_class: parlai.core.dict:DictionaryAgent\n",
      "17:23:23 |     dict_endtoken: __end__\n",
      "17:23:23 |     dict_file: model/memnn_prtr.dict\n",
      "17:23:23 |     dict_include_test: False\n",
      "17:23:23 |     dict_include_valid: False\n",
      "17:23:23 |     dict_initpath: None\n",
      "17:23:23 |     dict_language: english\n",
      "17:23:23 |     dict_loaded: True\n",
      "17:23:23 |     dict_lower: False\n",
      "17:23:23 |     dict_max_ngram_size: -1\n",
      "17:23:23 |     dict_maxexs: -1\n",
      "17:23:23 |     dict_maxtokens: -1\n",
      "17:23:23 |     dict_minfreq: 0\n",
      "17:23:23 |     dict_nulltoken: __null__\n",
      "17:23:23 |     dict_starttoken: __start__\n",
      "17:23:23 |     dict_textfields: text,labels\n",
      "17:23:23 |     dict_tokenizer: re\n",
      "17:23:23 |     dict_unktoken: __unk__\n",
      "17:23:23 |     display_examples: False\n",
      "17:23:23 |     download_path: None\n",
      "17:23:23 |     dynamic_batching: None\n",
      "17:23:23 |     embedding_projection: random\n",
      "17:23:23 |     embedding_size: 32\n",
      "17:23:23 |     embedding_type: random\n",
      "17:23:23 |     encode_candidate_vecs: True\n",
      "17:23:23 |     encode_candidate_vecs_batchsize: 256\n",
      "17:23:23 |     eval_batchsize: None\n",
      "17:23:23 |     eval_candidates: fixed\n",
      "17:23:23 |     eval_dynamic_batching: None\n",
      "17:23:23 |     evaltask: None\n",
      "17:23:23 |     fixed_candidate_vecs: reuse\n",
      "17:23:23 |     fixed_candidates_path: candidates.txt\n",
      "17:23:23 |     force_fp16_tokens: False\n",
      "17:23:23 |     fp16: False\n",
      "17:23:23 |     fp16_impl: safe\n",
      "17:23:23 |     gpu: -1\n",
      "17:23:23 |     gradient_clip: 0.1\n",
      "17:23:23 |     hide_labels: False\n",
      "17:23:23 |     history_add_global_end_token: None\n",
      "17:23:23 |     history_reversed: False\n",
      "17:23:23 |     history_size: 10\n",
      "17:23:23 |     hops: 3\n",
      "17:23:23 |     ignore_bad_candidates: True\n",
      "17:23:23 |     image_cropsize: 224\n",
      "17:23:23 |     image_mode: raw\n",
      "17:23:23 |     image_size: 256\n",
      "17:23:23 |     inference: max\n",
      "17:23:23 |     init_model: None\n",
      "17:23:23 |     init_opt: model/memnn_prtr.dict.opt\n",
      "17:23:23 |     interactive_candidates: fixed\n",
      "17:23:23 |     interactive_mode: False\n",
      "17:23:23 |     invsqrt_lr_decay_gamma: -1\n",
      "17:23:23 |     is_debug: False\n",
      "17:23:23 |     label_truncate: None\n",
      "17:23:23 |     learningrate: 0.01\n",
      "17:23:23 |     log_every_n_secs: -1\n",
      "17:23:23 |     log_every_n_steps: 50\n",
      "17:23:23 |     log_keep_fields: all\n",
      "17:23:23 |     loglevel: info\n",
      "17:23:23 |     lr_scheduler: fixed\n",
      "17:23:23 |     lr_scheduler_decay: 1.0\n",
      "17:23:23 |     lr_scheduler_patience: 3\n",
      "17:23:23 |     max_train_steps: -1\n",
      "17:23:23 |     max_train_time: -1\n",
      "17:23:23 |     memsize: 32\n",
      "17:23:23 |     metrics: default\n",
      "17:23:23 |     model: memnn\n",
      "17:23:23 |     model_file: model/memnn_prtr\n",
      "17:23:23 |     momentum: 0\n",
      "17:23:23 |     multitask_weights: [1]\n",
      "17:23:23 |     mutators: None\n",
      "17:23:23 |     nesterov: True\n",
      "17:23:23 |     no_cuda: False\n",
      "17:23:23 |     num_epochs: 100.0\n",
      "17:23:23 |     num_examples: -1\n",
      "17:23:23 |     num_workers: 0\n",
      "17:23:23 |     nus: [0.7]\n",
      "17:23:23 |     optimizer: sgd\n",
      "17:23:23 |     override: \"{'datatype': 'valid', 'task': 'flow:flow:2', 'init_opt': 'model/memnn_prtr.dict.opt', 'allow_missing_init_opts': True, 'datapath': '../flow_data', 'loglevel': 'info', 'image_mode': 'raw', 'hide_labels': False, 'multitask_weights': [1], 'batchsize': 100, 'dynamic_batching': None, 'is_debug': False, 'model': 'memnn', 'model_file': 'model/memnn_prtr', 'init_model': None, 'dict_class': 'parlai.core.dict:DictionaryAgent', 'evaltask': None, 'eval_batchsize': None, 'eval_dynamic_batching': None, 'num_workers': 0, 'display_examples': False, 'num_epochs': 100.0, 'max_train_time': -1, 'max_train_steps': -1, 'log_every_n_steps': 50, 'validation_every_n_secs': -1, 'validation_every_n_steps': -1, 'save_every_n_secs': -1, 'save_after_valid': False, 'validation_every_n_epochs': -1, 'validation_max_exs': -1, 'short_final_eval': False, 'validation_patience': 10, 'validation_metric': 'accuracy', 'validation_metric_mode': None, 'validation_cutoff': 1.0, 'validation_share_agent': False, 'metrics': 'default', 'aggregate_micro': False, 'tensorboard_log': True, 'tensorboard_logdir': None, 'wandb_log': False, 'wandb_name': None, 'wandb_project': None, 'wandb_entity': None, 'dict_maxexs': -1, 'dict_include_valid': False, 'dict_include_test': False, 'log_every_n_secs': -1, 'image_size': 256, 'image_cropsize': 224, 'mutators': None, 'embedding_size': 32, 'hops': 3, 'memsize': 32, 'time_features': False, 'position_encoding': True, 'embedding_type': 'random', 'embedding_projection': 'random', 'fp16': False, 'fp16_impl': 'safe', 'force_fp16_tokens': False, 'optimizer': 'sgd', 'learningrate': 0.01, 'gradient_clip': 0.1, 'adam_eps': 1e-08, 'adafactor_eps': [1e-30, 0.001], 'momentum': 0, 'nesterov': True, 'nus': [0.7], 'betas': [0.9, 0.999], 'weight_decay': None, 'rank_candidates': False, 'truncate': -1, 'text_truncate': None, 'label_truncate': None, 'history_reversed': False, 'history_size': 10, 'person_tokens': False, 'split_lines': True, 'use_reply': 'label', 'add_p1_after_newln': True, 'delimiter': '\\\\n', 'history_add_global_end_token': None, 'special_tok_lst': None, 'gpu': -1, 'no_cuda': False, 'lr_scheduler': 'fixed', 'lr_scheduler_patience': 3, 'lr_scheduler_decay': 1.0, 'invsqrt_lr_decay_gamma': -1, 'warmup_updates': -1, 'warmup_rate': 0.0001, 'update_freq': 1, 'candidates': 'fixed', 'eval_candidates': 'fixed', 'interactive_candidates': 'fixed', 'repeat_blocking_heuristic': True, 'fixed_candidates_path': 'candidates.txt', 'fixed_candidate_vecs': 'reuse', 'encode_candidate_vecs': True, 'encode_candidate_vecs_batchsize': 256, 'train_predict': False, 'cap_num_predictions': 100, 'ignore_bad_candidates': True, 'rank_top_k': -1, 'inference': 'max', 'topk': 5, 'return_cand_scores': False, 'dict_file': 'model/memnn_prtr.dict', 'dict_initpath': None, 'dict_language': 'english', 'dict_max_ngram_size': -1, 'dict_minfreq': 0, 'dict_maxtokens': -1, 'dict_nulltoken': '__null__', 'dict_starttoken': '__start__', 'dict_endtoken': '__end__', 'dict_unktoken': '__unk__', 'dict_tokenizer': 're', 'dict_lower': False, 'bpe_debug': False, 'dict_textfields': 'text,labels', 'bpe_vocab': None, 'bpe_merge': None, 'bpe_add_prefix_space': None, 'bpe_dropout': None, 'parlai_home': '/home/nazar/ParlAI', 'starttime': 'Jul23_15-36'}\"\n",
      "17:23:23 |     parlai_home: /home/nazar/ParlAI\n",
      "17:23:23 |     person_tokens: False\n",
      "17:23:23 |     position_encoding: True\n",
      "17:23:23 |     rank_candidates: True\n",
      "17:23:23 |     rank_top_k: -1\n",
      "17:23:23 |     repeat_blocking_heuristic: True\n",
      "17:23:23 |     report_filename: \n",
      "17:23:23 |     return_cand_scores: False\n",
      "17:23:23 |     save_after_valid: False\n",
      "17:23:23 |     save_every_n_secs: -1\n",
      "17:23:23 |     save_format: conversations\n",
      "17:23:23 |     short_final_eval: False\n",
      "17:23:23 |     special_tok_lst: None\n",
      "17:23:23 |     split_lines: True\n",
      "17:23:23 |     starttime: Jul23_15-36\n",
      "17:23:23 |     task: flow:flow:2\n",
      "17:23:23 |     tensorboard_log: True\n",
      "17:23:23 |     tensorboard_logdir: None\n",
      "17:23:23 |     text_truncate: None\n",
      "17:23:23 |     time_features: False\n",
      "17:23:23 |     topk: 5\n",
      "17:23:23 |     train_predict: False\n",
      "17:23:23 |     truncate: -1\n",
      "17:23:23 |     update_freq: 1\n",
      "17:23:23 |     use_reply: label\n",
      "17:23:23 |     validation_cutoff: 1.0\n",
      "17:23:23 |     validation_every_n_epochs: -1\n",
      "17:23:23 |     validation_every_n_secs: -1\n",
      "17:23:23 |     validation_every_n_steps: -1\n",
      "17:23:23 |     validation_max_exs: -1\n",
      "17:23:23 |     validation_metric: accuracy\n",
      "17:23:23 |     validation_metric_mode: None\n",
      "17:23:23 |     validation_patience: 10\n",
      "17:23:23 |     validation_share_agent: False\n",
      "17:23:23 |     verbose: False\n",
      "17:23:23 |     wandb_entity: None\n",
      "17:23:23 |     wandb_log: False\n",
      "17:23:23 |     wandb_name: None\n",
      "17:23:23 |     wandb_project: None\n",
      "17:23:23 |     warmup_rate: 0.0001\n",
      "17:23:23 |     warmup_updates: -1\n",
      "17:23:23 |     weight_decay: None\n",
      "17:23:23 |     world_logs: \n",
      "17:23:23 | Current ParlAI commit: cd646ddf9bb6b98119de45bb1454eae4bad57e5f\n",
      "17:23:24 | Evaluating task flow:flow:2 using datatype valid.\n",
      "17:23:24 | creating task(s): flow:flow:2\n",
      "17:23:24 | Loading ParlAI text data: ../flow_data/flow_valid_2.txt\n",
      "17:23:24 | Finished evaluating tasks ['flow:flow:2'] using datatype valid\n",
      "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  hits@1  hits@10  hits@100  hits@5  llen  loss  ltpb  ltps  ltrunc  \\\n",
      "       .3636   .3182  21.5  2017 514.4   22 .4208  .000112   .3636    .9545     .9545   .5455 13.41 5.404 73.75  6913       0   \n",
      "    ltrunclen   mrr  rank   tpb  tps  \n",
      "            0 .3234 5.133 95.25 8936\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'exs': SumMetric(22),\n",
       " 'accuracy': ExactMatchMetric(0.3636),\n",
       " 'f1': F1Metric(0.4208),\n",
       " 'bleu-4': BleuMetric(0.3182),\n",
       " 'hits@1': AverageMetric(0.3636),\n",
       " 'hits@5': AverageMetric(0.5455),\n",
       " 'hits@10': AverageMetric(0.9545),\n",
       " 'hits@100': AverageMetric(0.9545),\n",
       " 'llen': AverageMetric(13.41),\n",
       " 'ltrunc': AverageMetric(0),\n",
       " 'ltrunclen': AverageMetric(0),\n",
       " 'loss': AverageMetric(5.404),\n",
       " 'rank': AverageMetric(5.133),\n",
       " 'mrr': AverageMetric(0.3234),\n",
       " 'exps': GlobalTimerMetric(514.4),\n",
       " 'ltpb': GlobalAverageMetric(73.75),\n",
       " 'ltps': GlobalTimerMetric(6913),\n",
       " 'ctpb': GlobalAverageMetric(21.5),\n",
       " 'ctps': GlobalTimerMetric(2017),\n",
       " 'tpb': GlobalAverageMetric(95.25),\n",
       " 'tps': GlobalTimerMetric(8936),\n",
       " 'gpu_mem': GlobalAverageMetric(0.000112)}"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from parlai.scripts.eval_model import EvalModel\n",
    "\n",
    "EvalModel.main(\n",
    "    task='flow:flow:2:datapath=../flow_data,dialog_babi:task:5',\n",
    "    # task='dialog_babi:task:5',\n",
    "    # task='flow:flow:2',\n",
    "    model_file='model/memnn_prtr',\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "17:39:05 | \u001b[33mOverriding opt[\"datatype\"] to valid (previously: train)\u001b[0m\n",
      "17:39:05 | \u001b[33mOverriding opt[\"task\"] to flow:flow:2:datapath=../flow_data,dialog_babi:task:5 (previously: flow:flow:train:2)\u001b[0m\n",
      "17:39:05 | Using CUDA\n",
      "17:39:05 | loading dictionary from model/memnn_prtr.dict\n",
      "17:39:05 | num words = 148\n",
      "17:39:05 | Total parameters: 19,968 (19,968 trainable)\n",
      "17:39:05 | Loading existing model parameters from model/memnn_prtr\n",
      "17:39:05 | Loading fixed candidate set from candidates.txt\n",
      "17:39:05 | Loading fixed candidate set vectors from model/memnn_prtr.candidates.vecs\n",
      "17:39:05 | Loading fixed candidate set encodings from model/memnn_prtr.candidates.encs\n",
      "17:39:05 | Opt:\n",
      "17:39:05 |     adafactor_eps: '[1e-30, 0.001]'\n",
      "17:39:05 |     adam_eps: 1e-08\n",
      "17:39:05 |     add_p1_after_newln: True\n",
      "17:39:05 |     aggregate_micro: False\n",
      "17:39:05 |     allow_missing_init_opts: False\n",
      "17:39:05 |     area_under_curve_class: None\n",
      "17:39:05 |     area_under_curve_digits: -1\n",
      "17:39:05 |     batchsize: 100\n",
      "17:39:05 |     betas: '[0.9, 0.999]'\n",
      "17:39:05 |     bpe_add_prefix_space: None\n",
      "17:39:05 |     bpe_debug: False\n",
      "17:39:05 |     bpe_dropout: None\n",
      "17:39:05 |     bpe_merge: None\n",
      "17:39:05 |     bpe_vocab: None\n",
      "17:39:05 |     candidates: fixed\n",
      "17:39:05 |     cap_num_predictions: 100\n",
      "17:39:05 |     datapath: /home/nazar/ParlAI/data\n",
      "17:39:05 |     datatype: valid\n",
      "17:39:05 |     delimiter: '\\n'\n",
      "17:39:05 |     dict_class: parlai.core.dict:DictionaryAgent\n",
      "17:39:05 |     dict_endtoken: __end__\n",
      "17:39:05 |     dict_file: model/memnn_prtr.dict\n",
      "17:39:05 |     dict_include_test: False\n",
      "17:39:05 |     dict_include_valid: False\n",
      "17:39:05 |     dict_initpath: None\n",
      "17:39:05 |     dict_language: english\n",
      "17:39:05 |     dict_loaded: True\n",
      "17:39:05 |     dict_lower: False\n",
      "17:39:05 |     dict_max_ngram_size: -1\n",
      "17:39:05 |     dict_maxexs: -1\n",
      "17:39:05 |     dict_maxtokens: -1\n",
      "17:39:05 |     dict_minfreq: 0\n",
      "17:39:05 |     dict_nulltoken: __null__\n",
      "17:39:05 |     dict_starttoken: __start__\n",
      "17:39:05 |     dict_textfields: text,labels\n",
      "17:39:05 |     dict_tokenizer: re\n",
      "17:39:05 |     dict_unktoken: __unk__\n",
      "17:39:05 |     display_examples: False\n",
      "17:39:05 |     download_path: None\n",
      "17:39:05 |     dynamic_batching: None\n",
      "17:39:05 |     embedding_projection: random\n",
      "17:39:05 |     embedding_size: 32\n",
      "17:39:05 |     embedding_type: random\n",
      "17:39:05 |     encode_candidate_vecs: True\n",
      "17:39:05 |     encode_candidate_vecs_batchsize: 256\n",
      "17:39:05 |     eval_batchsize: None\n",
      "17:39:05 |     eval_candidates: fixed\n",
      "17:39:05 |     eval_dynamic_batching: None\n",
      "17:39:05 |     evaltask: None\n",
      "17:39:05 |     fixed_candidate_vecs: reuse\n",
      "17:39:05 |     fixed_candidates_path: candidates.txt\n",
      "17:39:05 |     force_fp16_tokens: False\n",
      "17:39:05 |     fp16: False\n",
      "17:39:05 |     fp16_impl: safe\n",
      "17:39:05 |     gpu: -1\n",
      "17:39:05 |     gradient_clip: 0.1\n",
      "17:39:05 |     hide_labels: False\n",
      "17:39:05 |     history_add_global_end_token: None\n",
      "17:39:05 |     history_reversed: False\n",
      "17:39:05 |     history_size: 10\n",
      "17:39:05 |     hops: 3\n",
      "17:39:05 |     ignore_bad_candidates: True\n",
      "17:39:05 |     image_cropsize: 224\n",
      "17:39:05 |     image_mode: raw\n",
      "17:39:05 |     image_size: 256\n",
      "17:39:05 |     inference: max\n",
      "17:39:05 |     init_model: model/memnn_prtr.checkpoint\n",
      "17:39:05 |     init_opt: None\n",
      "17:39:05 |     interactive_candidates: fixed\n",
      "17:39:05 |     interactive_mode: False\n",
      "17:39:05 |     invsqrt_lr_decay_gamma: -1\n",
      "17:39:05 |     is_debug: False\n",
      "17:39:05 |     label_truncate: None\n",
      "17:39:05 |     learningrate: 0.01\n",
      "17:39:05 |     log_every_n_secs: -1\n",
      "17:39:05 |     log_every_n_steps: 50\n",
      "17:39:05 |     log_keep_fields: all\n",
      "17:39:05 |     loglevel: info\n",
      "17:39:05 |     lr_scheduler: fixed\n",
      "17:39:05 |     lr_scheduler_decay: 1.0\n",
      "17:39:05 |     lr_scheduler_patience: 3\n",
      "17:39:05 |     max_train_steps: -1\n",
      "17:39:05 |     max_train_time: -1\n",
      "17:39:05 |     memsize: 32\n",
      "17:39:05 |     metrics: default\n",
      "17:39:05 |     model: memnn\n",
      "17:39:05 |     model_file: model/memnn_prtr\n",
      "17:39:05 |     momentum: 0\n",
      "17:39:05 |     multitask_weights: [1]\n",
      "17:39:05 |     mutators: None\n",
      "17:39:05 |     nesterov: True\n",
      "17:39:05 |     no_cuda: False\n",
      "17:39:05 |     num_epochs: 1000.0\n",
      "17:39:05 |     num_examples: -1\n",
      "17:39:05 |     num_workers: 0\n",
      "17:39:05 |     nus: [0.7]\n",
      "17:39:05 |     optimizer: sgd\n",
      "17:39:05 |     override: \"{'datatype': 'valid', 'task': 'flow:flow:2:datapath=../flow_data,dialog_babi:task:5', 'model_file': 'model/memnn_prtr'}\"\n",
      "17:39:05 |     parlai_home: /home/nazar/ParlAI\n",
      "17:39:05 |     person_tokens: False\n",
      "17:39:05 |     position_encoding: True\n",
      "17:39:05 |     rank_candidates: True\n",
      "17:39:05 |     rank_top_k: -1\n",
      "17:39:05 |     repeat_blocking_heuristic: True\n",
      "17:39:05 |     report_filename: \n",
      "17:39:05 |     return_cand_scores: False\n",
      "17:39:05 |     save_after_valid: False\n",
      "17:39:05 |     save_every_n_secs: 100.0\n",
      "17:39:05 |     save_format: conversations\n",
      "17:39:05 |     short_final_eval: False\n",
      "17:39:05 |     special_tok_lst: None\n",
      "17:39:05 |     split_lines: True\n",
      "17:39:05 |     starttime: Jul23_15-36\n",
      "17:39:05 |     task: flow:flow:2:datapath=../flow_data,dialog_babi:task:5\n",
      "17:39:05 |     tensorboard_log: True\n",
      "17:39:05 |     tensorboard_logdir: None\n",
      "17:39:05 |     text_truncate: None\n",
      "17:39:05 |     time_features: False\n",
      "17:39:05 |     topk: 5\n",
      "17:39:05 |     train_predict: False\n",
      "17:39:05 |     truncate: -1\n",
      "17:39:05 |     update_freq: 1\n",
      "17:39:05 |     use_reply: label\n",
      "17:39:05 |     validation_cutoff: 1.0\n",
      "17:39:05 |     validation_every_n_epochs: -1\n",
      "17:39:05 |     validation_every_n_secs: -1\n",
      "17:39:05 |     validation_every_n_steps: -1\n",
      "17:39:05 |     validation_max_exs: -1\n",
      "17:39:05 |     validation_metric: accuracy\n",
      "17:39:05 |     validation_metric_mode: None\n",
      "17:39:05 |     validation_patience: 10\n",
      "17:39:05 |     validation_share_agent: False\n",
      "17:39:05 |     verbose: False\n",
      "17:39:05 |     wandb_entity: None\n",
      "17:39:05 |     wandb_log: False\n",
      "17:39:05 |     wandb_name: None\n",
      "17:39:05 |     wandb_project: None\n",
      "17:39:05 |     warmup_rate: 0.0001\n",
      "17:39:05 |     warmup_updates: -1\n",
      "17:39:05 |     weight_decay: None\n",
      "17:39:05 |     world_logs: \n",
      "17:39:05 | Current ParlAI commit: cd646ddf9bb6b98119de45bb1454eae4bad57e5f\n",
      "17:39:05 | Evaluating task flow:flow:2:datapath=../flow_data using datatype valid.\n",
      "17:39:05 | creating task(s): flow:flow:2:datapath=../flow_data\n",
      "17:39:05 | Loading ParlAI text data: ../flow_data/flow_valid_2.txt\n",
      "17:39:05 | \u001b[33m[ Executing eval mode with a common set of fixed candidates (n = 10). ]\u001b[0m\n",
      "17:39:06 | Evaluating task dialog_babi:task:5 using datatype valid.\n",
      "17:39:06 | creating task(s): dialog_babi:task:5\n",
      "17:39:06 | loading fbdialog data: /home/nazar/ParlAI/data/dialog-bAbI/dialog-bAbI-tasks/dialog-babi-task5-full-dialogs-dev.txt\n",
      "17:39:16 | 16.0% complete (2,954 / 18,457), 0:00:10 elapsed, 0:00:52 eta\n",
      "    accuracy    bleu-4  ctpb  ctps  exps  exs     f1  gpu_mem  hits@1  hits@10  hits@100  hits@5  llen  ltpb  ltps  ltrunc  \\\n",
      "           0 1.765e-09 4.355  1287 295.4 2954 .05216 8.99e-05       0        0         0       0 6.902 6.902  2039       0   \n",
      "    ltrunclen   tpb  tps  \n",
      "            0 11.26 3325\n",
      "17:39:26 | 33.5% complete (6,189 / 18,457), 0:00:20 elapsed, 0:00:40 eta\n",
      "    accuracy    bleu-4  ctpb  ctps  exps  exs     f1   gpu_mem  hits@1  hits@10  hits@100  hits@5  llen  ltpb  ltps  ltrunc  \\\n",
      "           0 1.778e-09 4.352  1347 309.4 6189 .05295 9.701e-05       0        0         0       0 6.885 6.885  2130       0   \n",
      "    ltrunclen   tpb  tps  \n",
      "            0 11.24 3477\n",
      "17:39:36 | 51.4% complete (9,487 / 18,457), 0:00:30 elapsed, 0:00:28 eta\n",
      "    accuracy   bleu-4  ctpb  ctps  exps  exs     f1  gpu_mem  hits@1  hits@10  hits@100  hits@5  llen  ltpb  ltps  ltrunc  \\\n",
      "           0 1.86e-09 4.353  1376 316.2 9487 .05333 .0001019       0        0         0       0 6.887 6.887  2178       0   \n",
      "    ltrunclen   tpb  tps  \n",
      "            0 11.24 3554\n",
      "17:39:46 | 69.2% complete (12,764 / 18,457), 0:00:40 elapsed, 0:00:18 eta\n",
      "    accuracy   bleu-4  ctpb  ctps  exps   exs     f1  gpu_mem  hits@1  hits@10  hits@100  hits@5  llen  ltpb  ltps  ltrunc  \\\n",
      "           0 1.88e-09 4.358  1390   319 12764 .05321 .0001072       0        0         0       0  6.89  6.89  2198       0   \n",
      "    ltrunclen   tpb  tps  \n",
      "            0 11.25 3588\n",
      "17:39:56 | 87.2% complete (16,102 / 18,457), 0:00:50 elapsed, 0:00:07 eta\n",
      "    accuracy    bleu-4  ctpb  ctps  exps   exs     f1  gpu_mem  hits@1  hits@10  hits@100  hits@5  llen  ltpb  ltps  ltrunc  \\\n",
      "           0 1.772e-09 4.365  1405   322 16102 .05312 .0001133       0        0         0       0 6.891 6.891  2219       0   \n",
      "    ltrunclen   tpb  tps  \n",
      "            0 11.26 3624\n",
      "17:40:03 | Finished evaluating tasks ['flow:flow:2:datapath=../flow_data', 'dialog_babi:task:5'] using datatype valid\n",
      "                                      accuracy    bleu-4  ctpb  ctps  exps   exs     f1  gpu_mem  hits@1  hits@10  hits@100  \\\n",
      "   all                                   .1818     .1591 3.909 133.6 34.13 18479  .2369 .0001023   .1818    .4773     .4773   \n",
      "   dialog_babi:task:5                        0 1.773e-09                   18457 .05314                0        0         0   \n",
      "   flow:flow:2:datapath=../flow_data     .3636     .3182                      22  .4208            .3636    .9545     .9545   \n",
      "                                      hits@5  llen  loss  ltpb  ltps  ltrunc  ltrunclen   mrr  rank   tpb   tps  \n",
      "   all                                 .2955 10.15 3.996 13.41 458.1       0          0 .5167 3.952 17.32 591.7  \n",
      "   dialog_babi:task:5                      0 6.896                         0          0                          \n",
      "   flow:flow:2:datapath=../flow_data   .5909 13.41 3.996                   0          0 .5167 3.952\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'flow:flow:2:datapath=../flow_data/exs': SumMetric(22),\n",
       " 'exs': SumMetric(1.848e+04),\n",
       " 'flow:flow:2:datapath=../flow_data/accuracy': ExactMatchMetric(0.3636),\n",
       " 'flow:flow:2:datapath=../flow_data/f1': F1Metric(0.4208),\n",
       " 'flow:flow:2:datapath=../flow_data/bleu-4': BleuMetric(0.3182),\n",
       " 'flow:flow:2:datapath=../flow_data/hits@1': AverageMetric(0.3636),\n",
       " 'flow:flow:2:datapath=../flow_data/hits@5': AverageMetric(0.5909),\n",
       " 'flow:flow:2:datapath=../flow_data/hits@10': AverageMetric(0.9545),\n",
       " 'flow:flow:2:datapath=../flow_data/hits@100': AverageMetric(0.9545),\n",
       " 'flow:flow:2:datapath=../flow_data/llen': AverageMetric(13.41),\n",
       " 'flow:flow:2:datapath=../flow_data/ltrunc': AverageMetric(0),\n",
       " 'flow:flow:2:datapath=../flow_data/ltrunclen': AverageMetric(0),\n",
       " 'flow:flow:2:datapath=../flow_data/loss': AverageMetric(3.996),\n",
       " 'flow:flow:2:datapath=../flow_data/rank': AverageMetric(3.952),\n",
       " 'flow:flow:2:datapath=../flow_data/mrr': AverageMetric(0.5167),\n",
       " 'exps': GlobalTimerMetric(34.13),\n",
       " 'ltpb': GlobalAverageMetric(13.41),\n",
       " 'ltps': GlobalTimerMetric(458.1),\n",
       " 'ctpb': GlobalAverageMetric(3.909),\n",
       " 'ctps': GlobalTimerMetric(133.6),\n",
       " 'tpb': GlobalAverageMetric(17.32),\n",
       " 'tps': GlobalTimerMetric(591.7),\n",
       " 'gpu_mem': GlobalAverageMetric(0.0001023),\n",
       " 'dialog_babi:task:5/exs': SumMetric(1.846e+04),\n",
       " 'dialog_babi:task:5/accuracy': ExactMatchMetric(0),\n",
       " 'dialog_babi:task:5/f1': F1Metric(0.05314),\n",
       " 'dialog_babi:task:5/bleu-4': BleuMetric(1.773e-09),\n",
       " 'dialog_babi:task:5/hits@1': AverageMetric(0),\n",
       " 'dialog_babi:task:5/hits@5': AverageMetric(0),\n",
       " 'dialog_babi:task:5/hits@10': AverageMetric(0),\n",
       " 'dialog_babi:task:5/hits@100': AverageMetric(0),\n",
       " 'dialog_babi:task:5/llen': AverageMetric(6.896),\n",
       " 'dialog_babi:task:5/ltrunc': AverageMetric(0),\n",
       " 'dialog_babi:task:5/ltrunclen': AverageMetric(0),\n",
       " 'accuracy': MacroAverageMetric(0.1818),\n",
       " 'f1': MacroAverageMetric(0.2369),\n",
       " 'bleu-4': MacroAverageMetric(0.1591),\n",
       " 'hits@1': MacroAverageMetric(0.1818),\n",
       " 'hits@5': MacroAverageMetric(0.2955),\n",
       " 'hits@10': MacroAverageMetric(0.4773),\n",
       " 'hits@100': MacroAverageMetric(0.4773),\n",
       " 'llen': MacroAverageMetric(10.15),\n",
       " 'ltrunc': MacroAverageMetric(0),\n",
       " 'ltrunclen': MacroAverageMetric(0),\n",
       " 'loss': MacroAverageMetric(3.996),\n",
       " 'rank': MacroAverageMetric(3.952),\n",
       " 'mrr': MacroAverageMetric(0.5167)}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}